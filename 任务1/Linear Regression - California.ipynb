{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# çº¿æ€§å›å½’æ¨¡å‹è°ƒè¯•ä»»åŠ¡\n",
    "\n",
    "## æ¬¢è¿æ¥åˆ°AIä¸–ç•Œï¼\n",
    "\n",
    "åœ¨è¿™ä¸ªè€ƒè¯•ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€èµ·è°ƒè¯•ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨åŠ åˆ©ç¦å°¼äºšæˆ¿ä»·æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«äº†å¦‚æ”¶å…¥ä¸­ä½æ•°ã€æˆ¿é¾„ã€æˆ¿é—´æ•°é‡ã€åœ°ç†ä½ç½®ç­‰8ä¸ªç‰¹å¾ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªæ¨¡å‹æ¥å‡†ç¡®é¢„æµ‹åŒºåŸŸçš„æˆ¿ä»·ä¸­ä½æ•°ã€‚çº¿æ€§å›å½’æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€åŸºç¡€çš„ç®—æ³•ä¹‹ä¸€ï¼Œå°±åƒå­¦ä¹ æ•°å­¦è¦å…ˆå­¦ä¼šåŠ å‡æ³•ä¸€æ ·é‡è¦ï¼\n",
    "\n",
    "### æˆ‘ä»¬çš„ç›®æ ‡ï¼š\n",
    "- ç†è§£çº¿æ€§å›å½’çš„åŸºæœ¬åŸç†\n",
    "- å­¦ä¼šä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•\n",
    "- æŒæ¡PyTorchçš„åŸºæœ¬æ“ä½œ\n",
    "- é€šè¿‡è°ƒè¯•æ‰¾å‡ºä»£ç ä¸­çš„é—®é¢˜å¹¶ä¿®å¤\n",
    "\n",
    "## <font color='red'><b>ğŸ” è°ƒè¯•ä»»åŠ¡è¯´æ˜</b></font>\n",
    "\n",
    "<font color='red'><b>ä»»åŠ¡ç›®æ ‡ï¼šè¿™ä¸ªé¡¹ç›®ä¸­æœ‰å‡ å¤„ä»£ç éœ€è¦è°ƒè¯•å’Œä¿®å¤ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š</b></font>\n",
    "<br>\n",
    "<font color='red'><b>1. é€æ­¥æ‰§è¡Œæ­¤æ–‡æ¡£é‡Œçš„æ¯ä¸€æ­¥ä»£ç </b></font>\n",
    "<br>\n",
    "<font color='red'><b>2. ç†è§£ä»£ç çš„å«ä¹‰</b></font>\n",
    "<br>\n",
    "<font color='red'><b>3. æ ¹æ®ç¬¬6æ­¥å’Œç¬¬7æ­¥ä»£ç çš„æç¤ºï¼Œä¿®æ”¹ç›¸åº”çš„å‚æ•°ï¼Œä½¿å…¶è¾¾åˆ°ä»»åŠ¡è®¾å®šå€¼</b></font>\n",
    "\n",
    "è¯„åˆ†è§„åˆ™è¯´æ˜ï¼šéªŒè¯å‡†ç¡®ç‡åœ¨\n",
    "<br>\n",
    "åªå®Œæˆä»»åŠ¡1ï¼Œæœªå®Œæˆä»»åŠ¡2ï¼Œç»™10åˆ†ï¼›\n",
    "<br>\n",
    "åªå®Œæˆä»»åŠ¡2ï¼Œæœªå®Œæˆä»»åŠ¡1ï¼Œç»™15åˆ†ï¼›\n",
    "<br>\n",
    "å®Œæˆä»»åŠ¡1å’Œä»»åŠ¡2ï¼Œç»™25åˆ†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥å¿…è¦çš„å·¥å…·åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # æ•°å­¦è®¡ç®—å·¥å…·ç®±\n",
    "import pandas as pd  # æ•°æ®å¤„ç†å·¥å…·ç®±\n",
    "import torch  # æ·±åº¦å­¦ä¹ æ¡†æ¶\n",
    "import torch.nn as nn  # ç¥ç»ç½‘ç»œæ¨¡å—\n",
    "import matplotlib.pyplot as plt  # ç»˜å›¾å·¥å…·ç®±\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®å›¾åƒå¤§å°å’Œåˆ†è¾¨ç‡\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"æ‰€æœ‰å·¥å…·åŒ…å¯¼å…¥æˆåŠŸï¼\")\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬äºŒæ­¥ï¼šåŠ è½½å’Œäº†è§£æ•°æ®\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªç»å…¸çš„å›å½’é—®é¢˜æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨åŠ åˆ©ç¦å°¼äºšæˆ¿ä»·æ•°æ®é›†ä½œä¸ºæ›¿ä»£\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# åŠ è½½åŠ åˆ©ç¦å°¼äºšæˆ¿ä»·æ•°æ®é›†\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯\n",
    "print(\"ç‰¹å¾åç§°:\", california.feature_names)\n",
    "print(\"æ•°æ®å½¢çŠ¶:\", X.shape)\n",
    "print(\"ç›®æ ‡å˜é‡å½¢çŠ¶:\", y.shape)\n",
    "\n",
    "# è½¬æ¢ä¸ºDataFrameä¾¿äºæŸ¥çœ‹\n",
    "df = pd.DataFrame(X, columns=california.feature_names)\n",
    "df['Price'] = y\n",
    "print(df.head())\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# æŸ¥çœ‹æ•°æ®çš„åŸºæœ¬ä¿¡æ¯\n",
    "print(\"=== æ•°æ®åŸºæœ¬ä¿¡æ¯ ===\")\n",
    "print(f\"è®­ç»ƒé›†ç‰¹å¾å½¢çŠ¶: {X_train.shape}\")\n",
    "print(f\"è®­ç»ƒé›†æ ‡ç­¾å½¢çŠ¶: {y_train.shape}\")\n",
    "print(f\"æµ‹è¯•é›†ç‰¹å¾å½¢çŠ¶: {X_test.shape}\")\n",
    "print(f\"æµ‹è¯•é›†æ ‡ç­¾å½¢çŠ¶: {y_test.shape}\")\n",
    "print(f\"ç‰¹å¾æ•°é‡: {X_train.shape[1]}\")\n",
    "print(f\"ç‰¹å¾åç§°: {california.feature_names}\")  # ç§»é™¤äº† .tolist()\n",
    "\n",
    "# æ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬\n",
    "print(\"\\n=== å‰5ä¸ªæ ·æœ¬çš„ç‰¹å¾å€¼ ===\")\n",
    "for i in range(5):\n",
    "    print(f\"æ ·æœ¬ {i+1}: {X_train[i]} -> ä»·æ ¼: {y_train[i]:.2f}åƒç¾å…ƒ\")\n",
    "\n",
    "# æ•°æ®ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"\\n=== æ•°æ®ç»Ÿè®¡ä¿¡æ¯ ===\")\n",
    "print(f\"æˆ¿ä»·èŒƒå›´: {y.min():.2f} ~ {y.max():.2f}åƒç¾å…ƒ\")\n",
    "print(f\"å¹³å‡æˆ¿ä»·: {y.mean():.2f}åƒç¾å…ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸‰æ­¥ï¼šæ•°æ®é¢„å¤„ç†\n",
    "\n",
    "ä¸ºäº†è®©æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®æ ‡å‡†åŒ– - è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„æ­¥éª¤ï¼\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# åˆ›å»ºæ ‡å‡†åŒ–å™¨\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# å¯¹è®­ç»ƒé›†è¿›è¡Œæ ‡å‡†åŒ–\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "# å¯¹æµ‹è¯•é›†è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒé›†çš„å‚æ•°ï¼‰\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# è½¬æ¢ä¸ºPyTorchå¼ é‡\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train_scaled)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test_scaled)\n",
    "\n",
    "print(\"=== æ•°æ®é¢„å¤„ç†å®Œæˆ ===\")\n",
    "print(f\"æ ‡å‡†åŒ–åçš„è®­ç»ƒé›†ç‰¹å¾å½¢çŠ¶: {X_train_tensor.shape}\")\n",
    "print(f\"æ ‡å‡†åŒ–åçš„è®­ç»ƒé›†æ ‡ç­¾å½¢çŠ¶: {y_train_tensor.shape}\")\n",
    "print(f\"æ ‡å‡†åŒ–åçš„ç‰¹å¾å‡å€¼: {X_train_tensor.mean():.4f}\")\n",
    "print(f\"æ ‡å‡†åŒ–åçš„ç‰¹å¾æ ‡å‡†å·®: {X_train_tensor.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬å››æ­¥ï¼šç†è§£çº¿æ€§å›å½’åŸç†\n",
    "\n",
    "### çº¿æ€§å›å½’å…¬å¼ï¼š\n",
    "$$ y = w_1x_1 + w_2x_2 + ... + w_nx_n + b $$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $x_1, x_2, ..., x_n$ æ˜¯ç‰¹å¾ï¼ˆè¾“å…¥ï¼‰\n",
    "- $w_1, w_2, ..., w_n$ æ˜¯æƒé‡ï¼ˆéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼‰\n",
    "- $b$ æ˜¯åç½®é¡¹\n",
    "- $y$ æ˜¯é¢„æµ‹å€¼ï¼ˆè¾“å‡ºï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡½æ•°1ï¼šæ‰‹åŠ¨å®ç°çº¿æ€§å›å½’é¢„æµ‹å‡½æ•°\n",
    "def linear_regression_predict(X, weights, bias):\n",
    "    \"\"\"\n",
    "    æ‰‹åŠ¨å®ç°çº¿æ€§å›å½’é¢„æµ‹\n",
    "    \n",
    "    å‚æ•°:\n",
    "    X: è¾“å…¥ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º (æ ·æœ¬æ•°, ç‰¹å¾æ•°)\n",
    "    weights: æƒé‡ï¼Œå½¢çŠ¶ä¸º (ç‰¹å¾æ•°,)\n",
    "    bias: åç½®ï¼Œæ ‡é‡\n",
    "    \n",
    "    è¿”å›:\n",
    "    y_pred: é¢„æµ‹å€¼ï¼Œå½¢çŠ¶ä¸º (æ ·æœ¬æ•°,)\n",
    "    \"\"\"\n",
    "    # TODO: å®ç°çº¿æ€§å›å½’çš„é¢„æµ‹å…¬å¼\n",
    "    # æç¤ºï¼šä½¿ç”¨ torch.matmul æˆ– @ è¿ç®—ç¬¦è¿›è¡ŒçŸ©é˜µä¹˜æ³•\n",
    "    # æ³¨æ„ï¼šè¿™é‡Œæœ‰ä¸€ä¸ªéœ€è¦è°ƒè¯•çš„é—®é¢˜\n",
    "    y_pred = torch.matmul(X, weights) + bias  # è¯·æ£€æŸ¥è¿™è¡Œä»£ç æ˜¯å¦æœ‰é—®é¢˜\n",
    "    return y_pred\n",
    "\n",
    "# æµ‹è¯•é¢„æµ‹å‡½æ•°\n",
    "sample_weights = torch.randn(X_train_tensor.shape[1])  # éšæœºåˆå§‹åŒ–æƒé‡\n",
    "sample_bias = torch.randn(1)  # éšæœºåˆå§‹åŒ–åç½®\n",
    "\n",
    "predictions = linear_regression_predict(X_train_tensor, sample_weights, sample_bias)\n",
    "print(f\"é¢„æµ‹å€¼å½¢çŠ¶: {predictions.shape}\")\n",
    "print(f\"å‰5ä¸ªé¢„æµ‹å€¼: {predictions[:5]}\")\n",
    "print(f\"å¯¹åº”çš„çœŸå®å€¼: {y_train_tensor[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬äº”æ­¥ï¼šç†è§£æŸå¤±å‡½æ•°\n",
    "\n",
    "### å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰å…¬å¼ï¼š\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $y_i$ æ˜¯çœŸå®å€¼\n",
    "- $\\hat{y}_i$ æ˜¯é¢„æµ‹å€¼\n",
    "- $n$ æ˜¯æ ·æœ¬æ•°é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡½æ•°2ï¼šæ‰‹åŠ¨å®ç°å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°\n",
    "def mse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    è®¡ç®—å‡æ–¹è¯¯å·®æŸå¤±\n",
    "    \n",
    "    å‚æ•°:\n",
    "    y_true: çœŸå®å€¼ï¼Œå½¢çŠ¶ä¸º (æ ·æœ¬æ•°,)\n",
    "    y_pred: é¢„æµ‹å€¼ï¼Œå½¢çŠ¶ä¸º (æ ·æœ¬æ•°,)\n",
    "    \n",
    "    è¿”å›:\n",
    "    loss: å‡æ–¹è¯¯å·®æŸå¤±ï¼Œæ ‡é‡\n",
    "    \"\"\"\n",
    "    # TODO: å®ç°å‡æ–¹è¯¯å·®å…¬å¼\n",
    "    # æç¤ºï¼šå…ˆè®¡ç®—å·®å€¼ï¼Œç„¶åå¹³æ–¹ï¼Œæœ€åæ±‚å¹³å‡\n",
    "    # æ³¨æ„ï¼šè¿™é‡Œæœ‰ä¸€ä¸ªéœ€è¦è°ƒè¯•çš„é—®é¢˜\n",
    "    loss = torch.mean((y_true - y_pred) ** 2)  # è¯·æ£€æŸ¥è¿™è¡Œä»£ç æ˜¯å¦æœ‰é—®é¢˜\n",
    "    return loss\n",
    "\n",
    "# æµ‹è¯•æŸå¤±å‡½æ•°\n",
    "test_loss = mse_loss(y_train_tensor, predictions)\n",
    "print(f\"å½“å‰æ¨¡å‹çš„æŸå¤±: {test_loss:.4f}\")\n",
    "\n",
    "# ä½¿ç”¨PyTorchå†…ç½®å‡½æ•°éªŒè¯\n",
    "torch_loss = nn.MSELoss()(predictions, y_train_tensor)\n",
    "print(f\"PyTorchå†…ç½®æŸå¤±å‡½æ•°ç»“æœ: {torch_loss:.4f}\")\n",
    "print(f\"æˆ‘ä»¬çš„å®ç°æ˜¯å¦æ­£ç¡®: {torch.abs(test_loss - torch_loss) < 1e-6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬å…­æ­¥ï¼šé‡‡ç”¨æ¢¯åº¦ä¸‹é™å¯¹çº¿æ€§å›å½’æ¨¡å‹è¿›è¡Œå‚æ•°è®­ç»ƒ\n",
    "\n",
    "æ¢¯åº¦ä¸‹é™æ˜¯é€šè¿‡è®¡ç®—æŸå¤±å‡½æ•°å¯¹å‚æ•°çš„æ¢¯åº¦ï¼ˆå¯¼æ•°ï¼‰ï¼Œç„¶åæ²¿ç€æ¢¯åº¦åæ–¹å‘æ›´æ–°å‚æ•°æ¥æœ€å°åŒ–æŸå¤±å‡½æ•°çš„è¿‡ç¨‹ã€‚\n",
    "\n",
    "### å‚æ•°æ›´æ–°å…¬å¼ï¼š\n",
    "$$ w = w - \\alpha \\cdot \\frac{\\partial L}{\\partial w} $$\n",
    "$$ b = b - \\alpha \\cdot \\frac{\\partial L}{\\partial b} $$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $\\alpha$ æ˜¯å­¦ä¹ ç‡\n",
    "- $\\frac{\\partial L}{\\partial w}$ æ˜¯æŸå¤±å¯¹æƒé‡çš„æ¢¯åº¦\n",
    "- $\\frac{\\partial L}{\\partial b}$ æ˜¯æŸå¤±å¯¹åç½®çš„æ¢¯åº¦\n",
    "\n",
    "<div style=\"color: #FF0000; font-size: 18px; font-weight: bold; background-color: #FFF0F0; padding: 10px; border: 2px solid #FF0000; border-radius: 5px;\"> è€ƒè¯•ä»»åŠ¡1ï¼šä¸‹é¢çš„å‡½æ•°3ä¸­ï¼Œå…¶å®ƒå‚æ•°ä¸å˜ï¼Œä¿®æ”¹å­¦ä¹ ç‡ï¼Œä½¿å¾—æœ€åçš„æŸå¤±å‡½æ•°å€¼åœ¨0.4ä»¥ä¸‹ </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡½æ•°3ï¼šæ‰‹åŠ¨å®ç°æ¢¯åº¦ä¸‹é™\n",
    "def manual_gradient_descent(X, y, weights, bias, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    æ‰‹åŠ¨å®ç°æ¢¯åº¦ä¸‹é™\n",
    "    \n",
    "    å‚æ•°:\n",
    "    X: è¾“å…¥ç‰¹å¾\n",
    "    y: çœŸå®æ ‡ç­¾\n",
    "    weights: åˆå§‹æƒé‡\n",
    "    bias: åˆå§‹åç½®\n",
    "    learning_rate: å­¦ä¹ ç‡\n",
    "    epochs: è®­ç»ƒè½®æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    weights: è®­ç»ƒåçš„æƒé‡\n",
    "    bias: è®­ç»ƒåçš„åç½®\n",
    "    losses: æ¯è½®çš„æŸå¤±è®°å½•\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹å€¼\n",
    "        y_pred = linear_regression_predict(X, weights, bias)\n",
    "        \n",
    "        # è®¡ç®—æŸå¤±\n",
    "        loss = mse_loss(y, y_pred)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # æ‰‹åŠ¨è®¡ç®—æ¢¯åº¦\n",
    "        # å¯¹äºçº¿æ€§å›å½’ï¼Œæ¢¯åº¦çš„è®¡ç®—å…¬å¼ä¸ºï¼š\n",
    "        # dL/dw = (2/n) * X^T @ (y_pred - y)\n",
    "        # dL/db = (2/n) * sum(y_pred - y)\n",
    "        \n",
    "        n = len(y)\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # TODO: è®¡ç®—æƒé‡å’Œåç½®çš„æ¢¯åº¦\n",
    "        # æ³¨æ„ï¼šè¿™é‡Œæœ‰ä¸¤ä¸ªéœ€è¦è°ƒè¯•çš„é—®é¢˜\n",
    "        grad_weights = (2/n) * torch.matmul(X.T, error)  # è¯·æ£€æŸ¥è¿™è¡Œä»£ç \n",
    "        grad_bias = (2/n) * torch.sum(error)  # è¯·æ£€æŸ¥è¿™è¡Œä»£ç \n",
    "        \n",
    "        # æ›´æ–°å‚æ•°\n",
    "        weights = weights - learning_rate * grad_weights\n",
    "        bias = bias - learning_rate * grad_bias\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"è½®æ¬¡ {epoch}, æŸå¤±: {loss:.4f}\")\n",
    "    \n",
    "    return weights, bias, losses\n",
    "\n",
    "# æµ‹è¯•æ‰‹åŠ¨æ¢¯åº¦ä¸‹é™\n",
    "print(\"=== å¼€å§‹æ‰‹åŠ¨æ¢¯åº¦ä¸‹é™è®­ç»ƒ ===\")\n",
    "manual_weights = torch.randn(X_train_tensor.shape[1], requires_grad=False)\n",
    "manual_bias = torch.randn(1, requires_grad=False)\n",
    "\n",
    "final_weights, final_bias, manual_losses = manual_gradient_descent(\n",
    "    X_train_tensor, y_train_tensor, manual_weights, manual_bias, \n",
    "    learning_rate=0.01, epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nè®­ç»ƒå®Œæˆï¼æœ€ç»ˆæŸå¤±: {manual_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #FF0000; font-size: 18px; font-weight: bold; background-color: #FFF0F0; padding: 10px; border: 2px solid #FF0000; border-radius: 5px;\"> è€ƒè¯•ä»»åŠ¡2ï¼šä¸‹é¢çš„å‡½æ•°4ä¸­ï¼Œå…¶å®ƒå‚æ•°ä¸å˜ï¼Œä¿®æ”¹è®­ç»ƒè½®æ•°ï¼Œä½¿å¾—æœ€åçš„æŸå¤±å‡½æ•°å€¼åœ¨0.4ä»¥ä¸‹ </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡½æ•°4ï¼šæ‰‹åŠ¨å®ç°æ¢¯åº¦ä¸‹é™\n",
    "def manual_gradient_descent(X, y, weights, bias, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    æ‰‹åŠ¨å®ç°æ¢¯åº¦ä¸‹é™\n",
    "    \n",
    "    å‚æ•°:\n",
    "    X: è¾“å…¥ç‰¹å¾\n",
    "    y: çœŸå®æ ‡ç­¾\n",
    "    weights: åˆå§‹æƒé‡\n",
    "    bias: åˆå§‹åç½®\n",
    "    learning_rate: å­¦ä¹ ç‡\n",
    "    epochs: è®­ç»ƒè½®æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    weights: è®­ç»ƒåçš„æƒé‡\n",
    "    bias: è®­ç»ƒåçš„åç½®\n",
    "    losses: æ¯è½®çš„æŸå¤±è®°å½•\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹å€¼\n",
    "        y_pred = linear_regression_predict(X, weights, bias)\n",
    "        \n",
    "        # è®¡ç®—æŸå¤±\n",
    "        loss = mse_loss(y, y_pred)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # æ‰‹åŠ¨è®¡ç®—æ¢¯åº¦\n",
    "        # å¯¹äºçº¿æ€§å›å½’ï¼Œæ¢¯åº¦çš„è®¡ç®—å…¬å¼ä¸ºï¼š\n",
    "        # dL/dw = (2/n) * X^T @ (y_pred - y)\n",
    "        # dL/db = (2/n) * sum(y_pred - y)\n",
    "        \n",
    "        n = len(y)\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # TODO: è®¡ç®—æƒé‡å’Œåç½®çš„æ¢¯åº¦\n",
    "        # æ³¨æ„ï¼šè¿™é‡Œæœ‰ä¸¤ä¸ªéœ€è¦è°ƒè¯•çš„é—®é¢˜\n",
    "        grad_weights = (2/n) * torch.matmul(X.T, error)  # è¯·æ£€æŸ¥è¿™è¡Œä»£ç \n",
    "        grad_bias = (2/n) * torch.sum(error)  # è¯·æ£€æŸ¥è¿™è¡Œä»£ç \n",
    "        \n",
    "        # æ›´æ–°å‚æ•°\n",
    "        weights = weights - learning_rate * grad_weights\n",
    "        bias = bias - learning_rate * grad_bias\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"è½®æ¬¡ {epoch}, æŸå¤±: {loss:.4f}\")\n",
    "    \n",
    "    return weights, bias, losses\n",
    "\n",
    "# æµ‹è¯•æ‰‹åŠ¨æ¢¯åº¦ä¸‹é™\n",
    "print(\"=== å¼€å§‹æ‰‹åŠ¨æ¢¯åº¦ä¸‹é™è®­ç»ƒ ===\")\n",
    "manual_weights = torch.randn(X_train_tensor.shape[1], requires_grad=False)\n",
    "manual_bias = torch.randn(1, requires_grad=False)\n",
    "\n",
    "final_weights, final_bias, manual_losses = manual_gradient_descent(\n",
    "    X_train_tensor, y_train_tensor, manual_weights, manual_bias, \n",
    "    learning_rate=0.01, epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nè®­ç»ƒå®Œæˆï¼æœ€ç»ˆæŸå¤±: {manual_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
